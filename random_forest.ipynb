{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre: Keshava Tonathiu Sanchez Barbosa (418127029)\n",
    "### Materia: Machine Learning\n",
    "### Semestre: 4°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tarea: RF** (evaluada en la categoría _Otras evaluaciones_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Entrenar y ajustar un árbol de decisión para el conjunto de datos _Moon_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=10000, noise=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Dividir en conjunto de entrenamiento y de prueba utilizando ```train_test_split()```\n",
    "#### **Importante**: _Todas las pruebas_ se realizarán prediciendo sobre ```X_test``` y comparando dichas predicciones contra ```y_test```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Utilizar la búsqueda en malla con validación cruzada (con ayuda de la clase ```GridSearchCV```) para encontrar valores aceptables para los metaparámetros del ```DecisionTreeClassifier```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 294 candidates, totalling 882 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 882 out of 882 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], 'min_samples_split': [2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42), params, n_jobs=-1, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Mostrar el mejor estimador encontrado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=17,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 17, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Por omisión, ```GridSearchCV``` entrena el mejor modelo encontrado con todo el conjunto de datos (entrenamiento + prueba) al terminar la búsqueda (esto se puede cambiar pasándole a ```GridSearchCV``` el parámetro ```refit=False```). Con lo anterior, evaluamos la exactitud del modelo directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## **Trabajo a realizar**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este trabajo haremos la comparación de los resultados obtenidos al realizar GridSearchCV con la predicción que se logra obtener de entrenar arboles con los mejores parametros encontrados y posteriormente encontrando la predicción mas común."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.- Generar 1,000 subconjuntos del conjunto de entrenamiento ```X_train```, cada uno con 100 instancias seleccionadas aleatoriamente. La selección es con reemplazo, es decir, no _sacan_ de ```X_train``` las instancias que vayan seleccionando (y no olviden copiar también de ```y_train``` las etiquetas correspondientes). Pueden utilizar la clase ```ShuffleSplit``` de Scikit-Learn para esto.\n",
    "#### **Nota**.- No hay subconjuntos de validación aquí, todas las pruebas se harán contra ```X_test``` y ```y_test```, como se indicó más arriba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se hace uso de ShuffleSplit para obtener los conjuntos de indices para generar nuestros arboles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "random_split = ShuffleSplit(n_splits=1000, test_size=0, train_size=100, random_state=42)\n",
    "random_split.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se crea una lista de \"arboles\" donde almacenamos cada uno de los subconjuntos de indices que genero nuestro ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "arboles = []\n",
    "for train in random_split.split(X_train, y = None, groups = None):\n",
    "    arboles.append(train[0])\n",
    "print(len(arboles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.- Entrenar un árbol de decisión en cada subconjunto de 100 instancias, usando los mejores valores de los metaparámetros encontrados por la búsqueda en malla, es decir, el estimador devuelto por ```grid_search_cv.best_estimator_```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los arboles y sus conjuntos de soluciones a partir de un ciclo for,  posteriormente haciendo uso del best_estimator_ y best_params_ entrenamos cada uno de los arboles creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "arbol_shuffle = []\n",
    "arbol_entrenado = []\n",
    "y_train_2_electricbogaloo = []\n",
    "for i in range(len(arboles)):\n",
    "    arbol_actual = []\n",
    "    y_actual = []\n",
    "    for j in range(100):\n",
    "        indice = arboles[i][j]\n",
    "        arbol_actual.append(X_train[indice])\n",
    "        y_actual.append(y_train[indice])\n",
    "    arbol_shuffle.append(arbol_actual)\n",
    "    y_train_2_electricbogaloo.append(y_actual)\n",
    "        \n",
    "for i in range(len(arboles)):\n",
    "    tree_sk = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                max_features=None,\n",
    "                min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                min_samples_leaf=1,\n",
    "                min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
    "                splitter='best', max_leaf_nodes = 17, min_samples_split = 2)\n",
    "    arbol_entrenado.append(tree_sk.fit(arbol_shuffle[i], y_train_2_electricbogaloo[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.- Llega la magia: generar las predicciones de cada uno de los 1,000 árboles de decisión para cada instancia en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.- Evaluar cada uno de estos 1,000 árboles de decisión sobre el conjunto de prueba (```X_test``` y ```y_test```). Sólo deben calcular los 1,000 ```accuracy_score``` y promediarlos. Dado que los árboles se entrenarán con conjuntos de datos más pequeños que con el árbol de decisión determinado por la búsqueda en malla, la exactitud promedio de estos mil árboles será muy probablemente más baja (resultará un 80% de exactitud, aproximadamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8062925000000005\n"
     ]
    }
   ],
   "source": [
    "pred = []\n",
    "scores = []\n",
    "avg = 0\n",
    "for j in range(len(arbol_entrenado)):  \n",
    "    y_predict = arbol_entrenado[j].predict(X_test)\n",
    "    pred.append(y_predict)\n",
    "    score = accuracy_score(y_test, y_predict)\n",
    "    avg += score\n",
    "    scores.append(score)\n",
    "    \n",
    "avg /= 1000\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El promedio de las predicciones termina siendo menor que nuestra predicción por GridSearch (0.8695)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.- Conservar solamente la predicción más frecuente (se puede utilizar la función ```mode()``` de SciPy para esto). Esto corresponde a una predicción por mayoría de votos sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "moda = stats.mode(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.- Evaluar las predicciones conservadas ```y_pred_majority_votes``` contra el conjunto de prueba ```y_test```: se debe obtener un  ```accuracy_score``` ligeramente más alto que el del árbol de decisión de la búsqueda en malla (entre el 0.5 y el 1.5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "moda_score = accuracy_score(y_test, moda[0][0])\n",
    "print(moda_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, si obtenemos la moda de los resultados obtenidos podemos observar que este resultado es mejor que el obtenido por GridSearch (0.8695)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Podemos observar que existe una mejora entre nuestro resultado mas comun generado por los arboles (0.875) y el resultado generado por GridSearch (0.8695), parte de esto es por el algoritmo que se realiza con el entrenamiento de los arboles, y otra parte puede ser dada por los metaparametros obtenidos, lo cual mejora el accuracy de nuestro resultado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
